# ðŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

## æ ¸å¿ƒæ”¹è¿› - è§£å†³"çº¹ç†å¤åˆ¶"é—®é¢˜

ä¸»è¦æ”¹è¿›ç­–ç•¥:
1. âœ… **åˆ†ç±»ä»£æ›¿å›žå½’** - é¿å…æ¨¡åž‹å¤åˆ¶è½¨è¿¹ç‰¹å¾
2. âœ… **Dice Loss** - æ”¹å–„ç©ºé—´è¿žç»­æ€§
3. âœ… **æ•°æ®å¢žå¼º** - æé«˜æ³›åŒ–èƒ½åŠ›  
4. âœ… **æ›´æ·±çš„ç½‘ç»œ** - MONAI UNet (6å±‚)

### ä¸ºä»€ä¹ˆæœ‰æ•ˆ?
ç²’å­è½¨è¿¹å’ŒåŠ¿èƒ½åˆ†å¸ƒæ˜¯å®Œå…¨ä¸åŒçš„å›¾åƒæ¨¡å¼ã€‚ç›´æŽ¥å›žå½’ä¼šè®©æ¨¡åž‹å€¾å‘äºŽ"å¤åˆ¶"è¾“å…¥ç‰¹å¾ã€‚**åˆ†ç±»æ–¹æ³•**å¼ºåˆ¶æ¨¡åž‹å­¦ä¹ åŠ¿èƒ½çš„ç©ºé—´ç»“æž„,è€Œä¸æ˜¯åƒç´ å€¼,ä»Žè€Œé¿å…äº†çº¹ç†å¤åˆ¶é—®é¢˜ã€‚

## ä¸€é”®è¿è¡Œ

### 1. è®­ç»ƒæ¨¡åž‹
```bash
python train.py
```

**é¢„æœŸè¾“å‡º**:
```
å‡†å¤‡æ•°æ®é›†
å¼€å§‹è®­ç»ƒ
Epoch [1/200], Train Loss: 2.5432, Val Loss: 2.3456
Model saved at epoch 1 with val loss: 2.3456
...
```

### 2. è¿›è¡Œé¢„æµ‹
```bash
python predict_classification.py
```

**è¾“å‡º**:
- `predictions/pred_*.npy` - é¢„æµ‹çš„åŠ¿èƒ½å›¾
- `predictions/comparisons/*_comparison.png` - å¯è§†åŒ–å¯¹æ¯”å›¾

## å…³é”®é…ç½®

åœ¨ `config.py` ä¸­:
```python
NUM_CLASSES = 8        # åŠ¿èƒ½ç¦»æ•£åŒ–ä¸º8ä¸ªç­‰çº§
IMG_SIZE = 256        # å›¾åƒå¤§å°
BATCH_SIZE = 16       # æ‰¹æ¬¡å¤§å°
LEARNING_RATE = 1e-4  # å­¦ä¹ çŽ‡
EPOCHS = 200          # è®­ç»ƒè½®æ•°
```

## æ•°æ®ç›®å½•ç»“æž„

ç¡®ä¿ä½ çš„æ•°æ®æŒ‰ä»¥ä¸‹ç»“æž„ç»„ç»‡:
```
data_2000/
â”œâ”€â”€ trainA/          # è®­ç»ƒé›† - åŠ¿èƒ½å›¾(æ ‡ç­¾)
â”‚   â”œâ”€â”€ 0001.npy
â”‚   â”œâ”€â”€ 0002.npy
â”‚   â””â”€â”€ ...
â”œâ”€â”€ trainB/          # è®­ç»ƒé›† - è½¨è¿¹å›¾(è¾“å…¥)
â”‚   â”œâ”€â”€ 0001.npy
â”‚   â”œâ”€â”€ 0002.npy
â”‚   â””â”€â”€ ...
â”œâ”€â”€ validationA/     # éªŒè¯é›† - åŠ¿èƒ½å›¾
â”‚   â””â”€â”€ ...
â”œâ”€â”€ validationB/     # éªŒè¯é›† - è½¨è¿¹å›¾
â”‚   â””â”€â”€ ...
â”œâ”€â”€ testA/           # æµ‹è¯•é›† - åŠ¿èƒ½å›¾
â”‚   â””â”€â”€ ...
â””â”€â”€ testB/           # æµ‹è¯•é›† - è½¨è¿¹å›¾
    â””â”€â”€ ...
```

**æ³¨æ„**: Aæ˜¯åŠ¿èƒ½(target), Bæ˜¯è½¨è¿¹(input)

## æ ¸å¿ƒä»£ç å˜åŒ–

### Dataset (train.py):
```python
# å…³é”®æ”¹è¿›: ç¦»æ•£åŒ–æ ‡ç­¾
mask = (mask * NUM_CLASSES)  # è½¬æ¢ä¸º0-7çš„ç±»åˆ«
mask[mask >= NUM_CLASSES] = NUM_CLASSES - 1
mask[mask < 0] = 0
```

### Loss Function (train.py):
```python
def combined_loss(pred, target):
    ce = CrossEntropyLoss(pred, target)  # åˆ†ç±»
    dice = dice_loss_multiclass(pred, target)  # è¾¹ç•Œ
    return ce + dice
```

### Model (train.py):
```python
model = UNet(
    in_channels=1,
    out_channels=NUM_CLASSES,  # è¾“å‡º8ä¸ªç±»åˆ«!
    spatial_dims=2,
    channels=(32, 64, 128, 256, 320, 320),  # 6å±‚æ·±åº¦
    strides=(2, 2, 2, 2, 2),
)
```

### Prediction (predict_classification.py):
```python
outputs = model(images)  # (B, 8, H, W)
pred_classes = outputs.argmax(dim=1)  # èŽ·å–ç±»åˆ«
pred_values = pred_classes.float() / NUM_CLASSES  # è½¬ä¸º[0,1]
```

## ç›‘æŽ§è®­ç»ƒ

### æ­£å¸¸è®­ç»ƒåº”è¯¥çœ‹åˆ°:
```
Epoch [1/200], Train Loss: 2.5432, Val Loss: 2.3456
Epoch [2/200], Train Loss: 2.1234, Val Loss: 2.0123
Epoch [3/200], Train Loss: 1.8765, Val Loss: 1.7654
...
Epoch [50/200], Train Loss: 0.8234, Val Loss: 0.7654
Model saved at epoch 50 with val loss: 0.7654
```

### å¼‚å¸¸æƒ…å†µ:
- âŒ Lossä¸ä¸‹é™ â†’ æ£€æŸ¥å­¦ä¹ çŽ‡,é™ä½Žåˆ°5e-5
- âŒ Loss=NaN â†’ æ£€æŸ¥æ•°æ®èŒƒå›´,æ˜¯å¦æœ‰å¼‚å¸¸å€¼
- âŒ Val Lossä¸Šå‡ â†’ æ­£å¸¸,æ—©åœæœºåˆ¶ä¼šä¿å­˜æœ€ä½³æ¨¡åž‹

## è¯„ä¼°ç»“æžœ

è®­ç»ƒå®ŒæˆåŽ,ç”¨ä»¥ä¸‹æ–¹å¼æ£€æŸ¥:

### 1. æŸ¥çœ‹å¯¹æ¯”å›¾
```bash
# åœ¨ predictions/comparisons/ ç›®å½•ä¸‹
# æ‰“å¼€ä»»æ„ *_comparison.png æ–‡ä»¶
```

### 2. å®šé‡è¯„ä¼° (å¦‚æžœéœ€è¦)
```python
# è®¡ç®—MSE
from sklearn.metrics import mean_squared_error

pred = np.load('predictions/pred_0001.npy')
true = np.load('data_2000/testA/0001.npy')
mse = mean_squared_error(true.flatten(), pred.flatten())
print(f'MSE: {mse}')
```

## æ•…éšœæŽ’é™¤

### é—®é¢˜1: ImportError: No module named 'monai'
```bash
pip install monai
```

### é—®é¢˜2: CUDA out of memory
é™ä½Žbatch size:
```python
# config.py
BATCH_SIZE = 8  # æˆ–æ›´å°
```

### é—®é¢˜3: é¢„æµ‹ç»“æžœä»æœ‰è½¨è¿¹æ®‹ç•™
å°è¯•:
1. å¢žåŠ ç±»åˆ«æ•°: `NUM_CLASSES = 16`
2. å¢žåŠ Diceæƒé‡: `return ce + 2*dice`
3. è®­ç»ƒæ›´å¤šè½®æ¬¡

### é—®é¢˜4: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶
æ£€æŸ¥ `config.py` ä¸­çš„è·¯å¾„æ˜¯å¦æ­£ç¡®:
```python
DATA_DIR = '/lustre/home/2400011491/data/ai_train_data/data_2000'
```

## è¿›é˜¶è°ƒä¼˜

### å¦‚æžœæ•ˆæžœä¸é”™,å¯ä»¥å°è¯•:
1. **æ›´å¤šæ•°æ®å¢žå¼º**:
   ```python
   A.RandomBrightnessContrast(p=0.2)
   A.GaussianBlur(blur_limit=3, p=0.2)
   ```

2. **è°ƒæ•´ç±»åˆ«æ•°**:
   ```python
   NUM_CLASSES = 16  # æ›´ç»†ç²’åº¦
   ```

3. **ä½¿ç”¨ä½™å¼¦å­¦ä¹ çŽ‡è¡°å‡**:
   ```python
   scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
   ```

## ðŸ“– æ›´å¤šæ–‡æ¡£

- è¯¦ç»†æŠ€æœ¯è¯´æ˜Ž: `TRAINING_IMPROVEMENTS.md`
- å®Œæ•´æ–¹æ¡ˆè¯´æ˜Ž: `SOLUTION_SUMMARY.md`

---

**å°±è¿™ä¹ˆç®€å•!è¿è¡Œ `python train.py` å¼€å§‹è®­ç»ƒå§!** ðŸŽ‰
